{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "print(use_cuda)\n",
    "torch.manual_seed(1)\n",
    "batch_size = 128\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=True, download=True,\n",
    "                    transform=transforms.Compose([\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.RandomCrop(size=28),\n",
    "                        transforms.RandomRotation(degrees=7, fill=1),\n",
    "                        # transforms.RandomAffine(degrees=20, translate=(0.1,0.1), scale=(0.9, 1.1)),\n",
    "                        transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "                        transforms.Normalize((0.1307,), (0.3081,)), \n",
    "                        \n",
    "                    ])),\n",
    "    batch_size=batch_size, shuffle=True, **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Normalize((0.1307,), (0.3081,))\n",
    "                    ])),\n",
    "    batch_size=batch_size, shuffle=True, **kwargs)\n",
    "train_iter = iter(train_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, '4')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "batch_data = next(train_iter)\n",
    "imgs, labels = batch_data \n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(imgs[0].cpu().numpy().reshape((28,28)), cmap=\"gray\")\n",
    "plt.xlabel(labels[0].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model2 import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torchsummary in c:\\users\\sriharsha\\appdata\\roaming\\python\\python39\\site-packages (1.5.1)\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 8, 28, 28]              80\n",
      "              ReLU-2            [-1, 8, 28, 28]               0\n",
      "       BatchNorm2d-3            [-1, 8, 28, 28]              16\n",
      "           Dropout-4            [-1, 8, 28, 28]               0\n",
      "            Conv2d-5            [-1, 8, 28, 28]             584\n",
      "              ReLU-6            [-1, 8, 28, 28]               0\n",
      "       BatchNorm2d-7            [-1, 8, 28, 28]              16\n",
      "           Dropout-8            [-1, 8, 28, 28]               0\n",
      "            Conv2d-9           [-1, 10, 28, 28]             730\n",
      "             ReLU-10           [-1, 10, 28, 28]               0\n",
      "      BatchNorm2d-11           [-1, 10, 28, 28]              20\n",
      "          Dropout-12           [-1, 10, 28, 28]               0\n",
      "        MaxPool2d-13           [-1, 10, 14, 14]               0\n",
      "           Conv2d-14            [-1, 6, 14, 14]              66\n",
      "           Conv2d-15            [-1, 8, 14, 14]             440\n",
      "             ReLU-16            [-1, 8, 14, 14]               0\n",
      "      BatchNorm2d-17            [-1, 8, 14, 14]              16\n",
      "          Dropout-18            [-1, 8, 14, 14]               0\n",
      "           Conv2d-19           [-1, 12, 14, 14]             876\n",
      "             ReLU-20           [-1, 12, 14, 14]               0\n",
      "      BatchNorm2d-21           [-1, 12, 14, 14]              24\n",
      "          Dropout-22           [-1, 12, 14, 14]               0\n",
      "        MaxPool2d-23             [-1, 12, 7, 7]               0\n",
      "           Conv2d-24             [-1, 10, 7, 7]             130\n",
      "           Conv2d-25             [-1, 10, 7, 7]             910\n",
      "      BatchNorm2d-26             [-1, 10, 7, 7]              20\n",
      "             ReLU-27             [-1, 10, 7, 7]               0\n",
      "          Dropout-28             [-1, 10, 7, 7]               0\n",
      "           Conv2d-29             [-1, 10, 7, 7]             910\n",
      "      BatchNorm2d-30             [-1, 10, 7, 7]              20\n",
      "             ReLU-31             [-1, 10, 7, 7]               0\n",
      "          Dropout-32             [-1, 10, 7, 7]               0\n",
      "           Linear-33                   [-1, 10]           4,910\n",
      "================================================================\n",
      "Total params: 9,768\n",
      "Trainable params: 9,768\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.80\n",
      "Params size (MB): 0.04\n",
      "Estimated Total Size (MB): 0.84\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sriharsha\\Documents\\ERA-V6\\model2.py:92: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchsummary\n",
    "from torchsummary import summary\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "model = Model().to(device)\n",
    "summary(model, input_size=(1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    pbar = tqdm(train_loader)\n",
    "    for batch_idx, (data, target) in enumerate(pbar):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        pbar.set_description(desc= f'loss={loss.item()} batch_id={batch_idx}')\n",
    "\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/469 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.17645913362503052 batch_id=468: 100%|██████████| 469/469 [00:50<00:00,  9.20it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0730, Accuracy: 9774/10000 (97.74%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.05226840451359749 batch_id=468: 100%|██████████| 469/469 [00:50<00:00,  9.28it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0388, Accuracy: 9878/10000 (98.78%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.08491190522909164 batch_id=468: 100%|██████████| 469/469 [00:50<00:00,  9.28it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0408, Accuracy: 9876/10000 (98.76%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.051124002784490585 batch_id=468: 100%|██████████| 469/469 [00:50<00:00,  9.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0289, Accuracy: 9910/10000 (99.10%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.0842355489730835 batch_id=468: 100%|██████████| 469/469 [00:50<00:00,  9.35it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0224, Accuracy: 9933/10000 (99.33%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.06474775075912476 batch_id=468: 100%|██████████| 469/469 [00:49<00:00,  9.40it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0337, Accuracy: 9904/10000 (99.04%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.027794569730758667 batch_id=468: 100%|██████████| 469/469 [00:49<00:00,  9.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0247, Accuracy: 9924/10000 (99.24%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.004300772678107023 batch_id=468: 100%|██████████| 469/469 [00:49<00:00,  9.50it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0216, Accuracy: 9934/10000 (99.34%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.04587597772479057 batch_id=468: 100%|██████████| 469/469 [00:50<00:00,  9.26it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0207, Accuracy: 9936/10000 (99.36%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.03630325570702553 batch_id=468: 100%|██████████| 469/469 [00:50<00:00,  9.28it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0202, Accuracy: 9930/10000 (99.30%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.024780260398983955 batch_id=468: 100%|██████████| 469/469 [42:31<00:00,  5.44s/it]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0203, Accuracy: 9937/10000 (99.37%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.042807210236787796 batch_id=468: 100%|██████████| 469/469 [00:53<00:00,  8.83it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0224, Accuracy: 9921/10000 (99.21%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.05138729140162468 batch_id=468: 100%|██████████| 469/469 [00:52<00:00,  8.86it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0259, Accuracy: 9917/10000 (99.17%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.02268470823764801 batch_id=468: 100%|██████████| 469/469 [00:50<00:00,  9.21it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0204, Accuracy: 9937/10000 (99.37%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.02781677432358265 batch_id=468: 100%|██████████| 469/469 [00:54<00:00,  8.68it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0210, Accuracy: 9927/10000 (99.27%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.0376250185072422 batch_id=468: 100%|██████████| 469/469 [00:51<00:00,  9.13it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0201, Accuracy: 9931/10000 (99.31%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.008112812414765358 batch_id=468: 100%|██████████| 469/469 [00:51<00:00,  9.09it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0177, Accuracy: 9940/10000 (99.40%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.08848843723535538 batch_id=468: 100%|██████████| 469/469 [00:51<00:00,  9.18it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0184, Accuracy: 9934/10000 (99.34%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.047666534781455994 batch_id=468: 100%|██████████| 469/469 [00:55<00:00,  8.44it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0211, Accuracy: 9930/10000 (99.30%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = Model().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.03, momentum=0.9)\n",
    "\n",
    "for epoch in range(1, 20):\n",
    "    train(model, device, train_loader, optimizer, epoch)\n",
    "    test(model, device, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout_value = 0.05\n",
    "class Model2(nn.Module):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        # rin: 1, rout: 3, in_size: 28, out_size:28\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 4, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(4),\n",
    "            nn.Dropout(dropout_value)\n",
    "        )\n",
    "\n",
    "        # rin: 3, rout: 5, in_size: 28, out_size:28\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(4, 8, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.Dropout(dropout_value)\n",
    "        )\n",
    "\n",
    "        # rin: 5, rout: 6, in_size: 14, out_size:14\n",
    "        self.pool1 = nn.MaxPool2d(2,2)\n",
    "        self.ant1 = nn.Conv2d(8, 4, 1)\n",
    "\n",
    "        # rin: 6, rout: 10, in_size: 14, out_size:12\n",
    "        self.conv3 = nn.Sequential(nn.Conv2d(4, 6, 3),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.BatchNorm2d(6),\n",
    "                                    nn.Dropout(dropout_value)\n",
    "                                    )\n",
    "        \n",
    "        # rin: 10, rout: 14, in_size: 14, out_size:10\n",
    "        self.conv4 = nn.Sequential(nn.Conv2d(6, 8, 3),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.BatchNorm2d(8),\n",
    "                                    nn.Dropout(dropout_value)\n",
    "                                    )\n",
    "     \n",
    "\n",
    "        # rin: 14, rout: 18, in_size: 14, out_size:8\n",
    "        self.conv5 = nn.Sequential(nn.Conv2d(8, 10, 3),\n",
    "                                nn.ReLU(),\n",
    "                                nn.BatchNorm2d(10),\n",
    "                                nn.Dropout(dropout_value)\n",
    "                                )\n",
    "        \n",
    "                # rin: 18, rout: 22, in_size: 12, out_size:6\n",
    "        self.conv6 = nn.Sequential(nn.Conv2d(10, 10, 3),\n",
    "                                nn.ReLU(),\n",
    "                                nn.BatchNorm2d(10),\n",
    "                                nn.Dropout(dropout_value)\n",
    "                                )\n",
    "        \n",
    "             # rin: 22, rout: 26, in_size: 10, out_size:4\n",
    "        self.conv7 = nn.Sequential(nn.Conv2d(10, 10, 3),\n",
    "                                nn.ReLU(),\n",
    "                                nn.BatchNorm2d(10),\n",
    "                                nn.Dropout(dropout_value)\n",
    "                                )\n",
    "        \n",
    "        \n",
    "        # rin: 24, rout: 32, in_size: 8, out_size:2\n",
    "        self.conv8 = nn.Sequential(nn.Conv2d(10, 10, 3),nn.BatchNorm2d(10),nn.ReLU(), nn.Dropout(dropout_value))\n",
    "        self.linear = nn.Linear(10*2*2,10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.ant1(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.conv5(x)\n",
    "        x = self.conv6(x)\n",
    "        x = self.conv7(x)\n",
    "        x = self.conv8(x)\n",
    "        x = x.view(-1,10*2*2)\n",
    "        x = self.linear(x)\n",
    "        return F.log_softmax(x)\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# !pip install torchsummary\n",
    "# from torchsummary import summary\n",
    "# use_cuda = torch.cuda.is_available()\n",
    "# device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "# model = Model2().to(device)\n",
    "# summary(model, input_size=(1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# model = Model2().to(device)\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.04, momentum=0.9)\n",
    "\n",
    "# for epoch in range(1, 10):\n",
    "#     train(model, device, train_loader, optimizer, epoch)\n",
    "#     test(model, device, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
